{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "4003e766",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/bin/bash: /opt/conda/lib/libtinfo.so.6: no version information available (required by /bin/bash)\n",
      "Collecting git+https://github.com/oshadura/topcoffea.git@coffea-casa-analysis\n",
      "  Cloning https://github.com/oshadura/topcoffea.git (to revision coffea-casa-analysis) to /tmp/pip-req-build-9zf5jcvu\n",
      "Requirement already satisfied (use --upgrade to upgrade): topcoffea==0.0.0 from git+https://github.com/oshadura/topcoffea.git@coffea-casa-analysis in /home/cms-jovyan/topcoffea\n",
      "Building wheels for collected packages: topcoffea\n",
      "  Building wheel for topcoffea (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25h  Created wheel for topcoffea: filename=topcoffea-0.0.0-py3-none-any.whl size=4512948 sha256=e020a6dde8da5bedb5658fcf58b182244cc65fc5593209bae50ba8da1f429d85\n",
      "  Stored in directory: /tmp/pip-ephem-wheel-cache-b7hy8t1i/wheels/3a/95/24/bfbb2d1dc4571114a0106e7d0d6a8124bcd2ad9e72ec9ea14e\n",
      "Successfully built topcoffea\n"
     ]
    }
   ],
   "source": [
    "!pip install git+https://github.com/oshadura/topcoffea.git@coffea-casa-analysis\n",
    "#! pip install -e ."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "6bf8374a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import lz4.frame as lz4f\n",
    "import pickle\n",
    "import json\n",
    "import time\n",
    "import cloudpickle\n",
    "import gzip\n",
    "import os\n",
    "from optparse import OptionParser\n",
    "\n",
    "import uproot\n",
    "import numpy as np\n",
    "from coffea import hist, processor\n",
    "from coffea.util import load, save\n",
    "from coffea.nanoevents import NanoAODSchema\n",
    "\n",
    "from topcoffea.modules import samples\n",
    "from topcoffea.modules import fileReader\n",
    "\n",
    "#FIXME: analysis is not installed anywhere (should be installed as well)\n",
    "import topcoffea.analysis.topEFT.topeft\n",
    "\n",
    "import importlib.resources\n",
    "\n",
    "if hasattr(__builtins__,'__IPYTHON__'):\n",
    "    import sys\n",
    "    sys.argv = ['']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "050780c5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "jsonFile was selected for UNL /home/cms-jovyan/topcoffea/topcoffea/json/TTZToLLNuNu_M10.json\n"
     ]
    }
   ],
   "source": [
    "import argparse\n",
    "parser = argparse.ArgumentParser(description='You can customize your run')\n",
    "parser.add_argument('jsonFiles'           , nargs='?', help = 'Json file(s) containing files and metadata')\n",
    "parser.add_argument('--prefix', '-r'     , nargs='?', help = 'Prefix or redirector to look for the files')\n",
    "parser.add_argument('--test','-t'       , action='store_true'  , help = 'To perform a test, run over a few events in a couple of chunks')\n",
    "parser.add_argument('--pretend'        , action='store_true'  , help = 'Read json files but, not execute the analysis')\n",
    "#parser.add_argument('--nworkers','-n'   , default=8  , help = 'Number of workers')\n",
    "parser.add_argument('--chunksize','-s'   , default=500000  , help = 'Number of events per chunk')\n",
    "parser.add_argument('--nchunks','-c'   , default=None  , help = 'You can choose to run only a number of chunks')\n",
    "parser.add_argument('--outname','-o'   , default='plotsTopEFT', help = 'Name of the output file with histograms')\n",
    "parser.add_argument('--outpath','-p'   , default='histos', help = 'Name of the output directory')\n",
    "parser.add_argument('--treename'   , default='Events', help = 'Name of the tree inside the files')\n",
    "parser.add_argument('--do-errors', action='store_true', help = 'Save the w**2 coefficients')\n",
    "\n",
    "args = parser.parse_args()\n",
    "\n",
    "if args.jsonFiles is not None:\n",
    "  jsonFiles    = args.jsonFiles\n",
    "  print('jsonFiles {}'.format(args.jsonFiles))\n",
    "else:\n",
    "  with importlib.resources.path(\"topcoffea.json\", \"TTZToLLNuNu_M10.json\") as path:\n",
    "    jsonFiles = str(path)\n",
    "    print('jsonFile was selected for UNL {}'.format(jsonFiles))\n",
    "    \n",
    "if args.prefix is not None:\n",
    "  prefix    = args.prefix\n",
    "else:\n",
    "  prefix = \"root://xcache//\"\n",
    "\n",
    "dotest     = args.test\n",
    "#nworkers   = int(args.nworkers)\n",
    "chunksize  = int(args.chunksize)\n",
    "nchunks    = int(args.nchunks) if not args.nchunks is None else args.nchunks\n",
    "outname    = args.outname\n",
    "outpath    = args.outpath\n",
    "pretend    = args.pretend\n",
    "treename   = args.treename\n",
    "do_errors = args.do_errors\n",
    "\n",
    "if dotest:\n",
    "  nchunks = 2\n",
    "  chunksize = 10000\n",
    "  nworkers = 1\n",
    "  print('Running a fast test with %i workers, %i chunks of %i events'%(nworkers, nchunks, chunksize))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "7886a0e3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['/home/cms-jovyan/topcoffea/topcoffea/json/TTZToLLNuNu_M10.json']\n",
      ">> TTZToLLNuNu_M10\n",
      "   - isData?      : NO\n",
      "   - year         : 2018\n",
      "   - xsec         : 0.252900\n",
      "   - histAxisName : \n",
      "   - options      : \n",
      "   - tree         : Events\n",
      "   - nEvents      : 14542666\n",
      "   - nGenEvents   : 4876491\n",
      "   - SumWeights   : 19992000.000000\n",
      "   - Prefix       : root://xcache//\n",
      "   - nFiles       : 18\n",
      "     /store/user/jrgonzal/nanoAODcrab/TTZToLLNuNu_M-10_TuneCP5_13TeV-amcatnlo-pythia8/mc2018_28apr2021_TTZToLLNuNu_M-10_TuneCP5_13TeV-amcatnlo-pythia8/210427_230816/0000/tree_1.root\n",
      "     /store/user/jrgonzal/nanoAODcrab/TTZToLLNuNu_M-10_TuneCP5_13TeV-amcatnlo-pythia8/mc2018_28apr2021_TTZToLLNuNu_M-10_TuneCP5_13TeV-amcatnlo-pythia8/210427_230816/0000/tree_10.root\n",
      "     /store/user/jrgonzal/nanoAODcrab/TTZToLLNuNu_M-10_TuneCP5_13TeV-amcatnlo-pythia8/mc2018_28apr2021_TTZToLLNuNu_M-10_TuneCP5_13TeV-amcatnlo-pythia8/210427_230816/0000/tree_11.root\n",
      "     /store/user/jrgonzal/nanoAODcrab/TTZToLLNuNu_M-10_TuneCP5_13TeV-amcatnlo-pythia8/mc2018_28apr2021_TTZToLLNuNu_M-10_TuneCP5_13TeV-amcatnlo-pythia8/210427_230816/0000/tree_12.root\n",
      "     /store/user/jrgonzal/nanoAODcrab/TTZToLLNuNu_M-10_TuneCP5_13TeV-amcatnlo-pythia8/mc2018_28apr2021_TTZToLLNuNu_M-10_TuneCP5_13TeV-amcatnlo-pythia8/210427_230816/0000/tree_13.root\n",
      "     /store/user/jrgonzal/nanoAODcrab/TTZToLLNuNu_M-10_TuneCP5_13TeV-amcatnlo-pythia8/mc2018_28apr2021_TTZToLLNuNu_M-10_TuneCP5_13TeV-amcatnlo-pythia8/210427_230816/0000/tree_14.root\n",
      "     /store/user/jrgonzal/nanoAODcrab/TTZToLLNuNu_M-10_TuneCP5_13TeV-amcatnlo-pythia8/mc2018_28apr2021_TTZToLLNuNu_M-10_TuneCP5_13TeV-amcatnlo-pythia8/210427_230816/0000/tree_15.root\n",
      "     /store/user/jrgonzal/nanoAODcrab/TTZToLLNuNu_M-10_TuneCP5_13TeV-amcatnlo-pythia8/mc2018_28apr2021_TTZToLLNuNu_M-10_TuneCP5_13TeV-amcatnlo-pythia8/210427_230816/0000/tree_16.root\n",
      "     /store/user/jrgonzal/nanoAODcrab/TTZToLLNuNu_M-10_TuneCP5_13TeV-amcatnlo-pythia8/mc2018_28apr2021_TTZToLLNuNu_M-10_TuneCP5_13TeV-amcatnlo-pythia8/210427_230816/0000/tree_17.root\n",
      "     /store/user/jrgonzal/nanoAODcrab/TTZToLLNuNu_M-10_TuneCP5_13TeV-amcatnlo-pythia8/mc2018_28apr2021_TTZToLLNuNu_M-10_TuneCP5_13TeV-amcatnlo-pythia8/210427_230816/0000/tree_18.root\n",
      "     /store/user/jrgonzal/nanoAODcrab/TTZToLLNuNu_M-10_TuneCP5_13TeV-amcatnlo-pythia8/mc2018_28apr2021_TTZToLLNuNu_M-10_TuneCP5_13TeV-amcatnlo-pythia8/210427_230816/0000/tree_2.root\n",
      "     /store/user/jrgonzal/nanoAODcrab/TTZToLLNuNu_M-10_TuneCP5_13TeV-amcatnlo-pythia8/mc2018_28apr2021_TTZToLLNuNu_M-10_TuneCP5_13TeV-amcatnlo-pythia8/210427_230816/0000/tree_3.root\n",
      "     /store/user/jrgonzal/nanoAODcrab/TTZToLLNuNu_M-10_TuneCP5_13TeV-amcatnlo-pythia8/mc2018_28apr2021_TTZToLLNuNu_M-10_TuneCP5_13TeV-amcatnlo-pythia8/210427_230816/0000/tree_4.root\n",
      "     /store/user/jrgonzal/nanoAODcrab/TTZToLLNuNu_M-10_TuneCP5_13TeV-amcatnlo-pythia8/mc2018_28apr2021_TTZToLLNuNu_M-10_TuneCP5_13TeV-amcatnlo-pythia8/210427_230816/0000/tree_5.root\n",
      "     /store/user/jrgonzal/nanoAODcrab/TTZToLLNuNu_M-10_TuneCP5_13TeV-amcatnlo-pythia8/mc2018_28apr2021_TTZToLLNuNu_M-10_TuneCP5_13TeV-amcatnlo-pythia8/210427_230816/0000/tree_6.root\n",
      "     /store/user/jrgonzal/nanoAODcrab/TTZToLLNuNu_M-10_TuneCP5_13TeV-amcatnlo-pythia8/mc2018_28apr2021_TTZToLLNuNu_M-10_TuneCP5_13TeV-amcatnlo-pythia8/210427_230816/0000/tree_7.root\n",
      "     /store/user/jrgonzal/nanoAODcrab/TTZToLLNuNu_M-10_TuneCP5_13TeV-amcatnlo-pythia8/mc2018_28apr2021_TTZToLLNuNu_M-10_TuneCP5_13TeV-amcatnlo-pythia8/210427_230816/0000/tree_8.root\n",
      "     /store/user/jrgonzal/nanoAODcrab/TTZToLLNuNu_M-10_TuneCP5_13TeV-amcatnlo-pythia8/mc2018_28apr2021_TTZToLLNuNu_M-10_TuneCP5_13TeV-amcatnlo-pythia8/210427_230816/0000/tree_9.root\n"
     ]
    }
   ],
   "source": [
    "\n",
    "samplesdict = {}\n",
    "allInputFiles = []\n",
    "\n",
    "def LoadJsonToSampleName(jsonFile, prefix):\n",
    "  sampleName = jsonFile if not '/' in jsonFile else jsonFile[jsonFile.rfind('/')+1:]\n",
    "  if sampleName.endswith('.json'): sampleName = sampleName[:-5]\n",
    "  with open(jsonFile) as jf:\n",
    "    samplesdict[sampleName] = json.load(jf)\n",
    "    samplesdict[sampleName]['redirector'] = prefix\n",
    "\n",
    "if  isinstance(jsonFiles, str) and ',' in jsonFiles: jsonFiles = jsonFiles.replace(' ', '').split(',')\n",
    "elif isinstance(jsonFiles, str)                     : jsonFiles = [jsonFiles]\n",
    "\n",
    "for jsonFile in jsonFiles:\n",
    "  if os.path.isdir(jsonFile):\n",
    "    if not jsonFile.endswith('/'): jsonFile+='/'\n",
    "    for f in os.path.listdir(jsonFile):\n",
    "      if f.endswith('.json'): allInputFiles.append(jsonFile+f)\n",
    "  else:\n",
    "    allInputFiles.append(jsonFile)\n",
    "\n",
    "print(allInputFiles)\n",
    "# Read from cfg files\n",
    "for f in allInputFiles:\n",
    "  if not os.path.isfile(f):\n",
    "    print('[WARNING] Input file \"%s% not found!'%f)\n",
    "    continue\n",
    "  # This input file is a json file, not a cfg\n",
    "  if f.endswith('.json'): \n",
    "    LoadJsonToSampleName(f, prefix)\n",
    "  # Open cfg files\n",
    "  else:\n",
    "    with open(f) as fin:\n",
    "      print(' >> Reading json from cfg file...')\n",
    "      lines = fin.readlines()\n",
    "      for l in lines:\n",
    "        if '#' in l: l=l[:l.find('#')]\n",
    "        l = l.replace(' ', '').replace('\\n', '')\n",
    "        if l == '': continue\n",
    "        if ',' in l:\n",
    "          l = l.split(',')\n",
    "          for nl in l:\n",
    "            if not os.path.isfile(l): prefix = nl\n",
    "            else: LoadJsonToSampleName(nl, prefix)\n",
    "        else:\n",
    "          if not os.path.isfile(l): prefix = l\n",
    "          else: LoadJsonToSampleName(l, prefix)\n",
    "\n",
    "flist = {};\n",
    "for sname in samplesdict.keys():\n",
    "  redirector = samplesdict[sname]['redirector']\n",
    "  flist[sname] = [(redirector+f) for f in samplesdict[sname]['files']]\n",
    "  samplesdict[sname]['year'] = int(samplesdict[sname]['year'])\n",
    "  samplesdict[sname]['xsec'] = float(samplesdict[sname]['xsec'])\n",
    "  samplesdict[sname]['nEvents'] = int(samplesdict[sname]['nEvents'])\n",
    "  samplesdict[sname]['nGenEvents'] = int(samplesdict[sname]['nGenEvents'])\n",
    "  samplesdict[sname]['nSumOfWeights'] = float(samplesdict[sname]['nSumOfWeights'])\n",
    "\n",
    "  # Print file info\n",
    "  print('>> '+sname)\n",
    "  print('   - isData?      : %s'   %('YES' if samplesdict[sname]['isData'] else 'NO'))\n",
    "  print('   - year         : %i'   %samplesdict[sname]['year'])\n",
    "  print('   - xsec         : %f'   %samplesdict[sname]['xsec'])\n",
    "  print('   - histAxisName : %s'   %samplesdict[sname]['histAxisName'])\n",
    "  print('   - options      : %s'   %samplesdict[sname]['options'])\n",
    "  print('   - tree         : %s'   %samplesdict[sname]['treeName'])\n",
    "  print('   - nEvents      : %i'   %samplesdict[sname]['nEvents'])\n",
    "  print('   - nGenEvents   : %i'   %samplesdict[sname]['nGenEvents'])\n",
    "  print('   - SumWeights   : %f'   %samplesdict[sname]['nSumOfWeights'])\n",
    "  print('   - Prefix       : %s'   %samplesdict[sname]['redirector'])\n",
    "  print('   - nFiles       : %i'   %len(samplesdict[sname]['files']))\n",
    "  for fname in samplesdict[sname]['files']: print('     %s'%fname)\n",
    "\n",
    "if pretend: \n",
    "  print('pretending...')\n",
    "  exit() \n",
    "\n",
    "# Check that all datasets have the same list of WCs\n",
    "for i,k in enumerate(samplesdict.keys()):\n",
    "  if i == 0:\n",
    "    wc_lst = samplesdict[k]['WCnames']\n",
    "  if wc_lst != samplesdict[k]['WCnames']:\n",
    "    raise Exception(\"Not all of the datasets have the same list of WCs.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "a0d806f4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[#################################       ] | 84% Completed | 18min 59.9s"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-5-c945cb44fc95>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     23\u001b[0m \u001b[0;31m# Run the processor and get the output\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     24\u001b[0m \u001b[0mtstart\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 25\u001b[0;31m output = processor.run_uproot_job(flist,\n\u001b[0m\u001b[1;32m     26\u001b[0m                                   \u001b[0mtreename\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtreename\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     27\u001b[0m                                   \u001b[0mprocessor_instance\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mprocessor_instance\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.8/site-packages/coffea/processor/executor.py\u001b[0m in \u001b[0;36mrun_uproot_job\u001b[0;34m(fileset, treename, processor_instance, executor, executor_args, pre_executor, pre_args, chunksize, maxchunks, metadata_cache)\u001b[0m\n\u001b[1;32m   1160\u001b[0m             }\n\u001b[1;32m   1161\u001b[0m             \u001b[0mpre_args\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpre_arg_override\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1162\u001b[0;31m             \u001b[0mout\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpre_executor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mto_get\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmetadata_fetcher\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mout\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mpre_args\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1163\u001b[0m             \u001b[0;32mwhile\u001b[0m \u001b[0mout\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1164\u001b[0m                 \u001b[0mitem\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mout\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpop\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.8/site-packages/coffea/processor/executor.py\u001b[0m in \u001b[0;36mdask_executor\u001b[0;34m(items, function, accumulator, **kwargs)\u001b[0m\n\u001b[1;32m    744\u001b[0m             \u001b[0;32mfrom\u001b[0m \u001b[0mdistributed\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mprogress\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    745\u001b[0m             \u001b[0;31m# FIXME: fancy widget doesn't appear, have to live with boring pbar\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 746\u001b[0;31m             \u001b[0mprogress\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mwork\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmulti\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnotebook\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    747\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0maccumulate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mwork\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mresult\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mclevel\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0m_decompress\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mwork\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mresult\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maccumulator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    748\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.8/site-packages/distributed/diagnostics/progressbar.py\u001b[0m in \u001b[0;36mprogress\u001b[0;34m(notebook, multi, complete, *futures, **kwargs)\u001b[0m\n\u001b[1;32m    437\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mbar\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    438\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 439\u001b[0;31m         \u001b[0mTextProgressBar\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfutures\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcomplete\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcomplete\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/opt/conda/lib/python3.8/site-packages/distributed/diagnostics/progressbar.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, keys, scheduler, interval, width, loop, complete, start, **kwargs)\u001b[0m\n\u001b[1;32m    120\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mstart\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    121\u001b[0m             \u001b[0mloop_runner\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mLoopRunner\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mloop\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 122\u001b[0;31m             \u001b[0mloop_runner\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun_sync\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlisten\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    123\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    124\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_draw_bar\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mremaining\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mall\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.8/site-packages/distributed/utils.py\u001b[0m in \u001b[0;36mrun_sync\u001b[0;34m(self, func, *args, **kwargs)\u001b[0m\n\u001b[1;32m    507\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstart\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    508\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 509\u001b[0;31m                 \u001b[0;32mreturn\u001b[0m \u001b[0msync\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mloop\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    510\u001b[0m             \u001b[0;32mfinally\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    511\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstop\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.8/site-packages/distributed/utils.py\u001b[0m in \u001b[0;36msync\u001b[0;34m(loop, func, callback_timeout, *args, **kwargs)\u001b[0m\n\u001b[1;32m    348\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    349\u001b[0m         \u001b[0;32mwhile\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mis_set\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 350\u001b[0;31m             \u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m10\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    351\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0merror\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    352\u001b[0m         \u001b[0mtyp\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mexc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0merror\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.8/threading.py\u001b[0m in \u001b[0;36mwait\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    556\u001b[0m             \u001b[0msignaled\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_flag\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    557\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0msignaled\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 558\u001b[0;31m                 \u001b[0msignaled\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_cond\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    559\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0msignaled\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    560\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.8/threading.py\u001b[0m in \u001b[0;36mwait\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    304\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    305\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mtimeout\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 306\u001b[0;31m                     \u001b[0mgotit\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mwaiter\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0macquire\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    307\u001b[0m                 \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    308\u001b[0m                     \u001b[0mgotit\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mwaiter\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0macquire\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "processor_instance = topcoffea.analysis.topEFT.topeft.AnalysisProcessor(samplesdict,wc_lst,do_errors)\n",
    "\n",
    "from dask.distributed import Client, Worker, WorkerPlugin\n",
    "import os\n",
    "from typing import List\n",
    "class DependencyInstaller(WorkerPlugin):\n",
    "    def __init__(self, dependencies: List[str]):\n",
    "        self._depencendies = \" \".join(f\"'{dep}'\" for dep in dependencies)\n",
    "    def setup(self, worker: Worker):\n",
    "        os.system(f\"pip install {self._depencendies}\")\n",
    "dependency_installer = DependencyInstaller([\n",
    "    \"git+https://github.com/oshadura/topcoffea.git@coffea-casa-analysis\"\n",
    "])\n",
    "\n",
    "client = Client(\"tls://localhost:8786\")\n",
    "client.register_worker_plugin(dependency_installer)\n",
    "\n",
    "executor_args = {\n",
    "                 'schema': NanoAODSchema,\n",
    "                 'client': client\n",
    "}\n",
    "\n",
    "# Run the processor and get the output                                                                                                                                                                     \n",
    "tstart = time.time()\n",
    "output = processor.run_uproot_job(flist,\n",
    "                                  treename=treename,\n",
    "                                  processor_instance=processor_instance,\n",
    "                                  executor=processor.dask_executor,\n",
    "                                  executor_args=executor_args,\n",
    "                                  chunksize=chunksize,\n",
    "                                  maxchunks=nchunks\n",
    "                                 )\n",
    "dt = time.time() - tstart\n",
    "\n",
    "nbins = sum(sum(arr.size for arr in h._sumw.values()) for h in output.values() if isinstance(h, hist.Hist))\n",
    "nfilled = sum(sum(np.sum(arr > 0) for arr in h._sumw.values()) for h in output.values() if isinstance(h, hist.Hist))\n",
    "print(\"Filled %.0f bins, nonzero bins: %1.1f %%\" % (nbins, 100*nfilled/nbins,))\n",
    "print(\"Processing time: %1.2f s with %i workers (%.2f s cpu overall)\" % (dt, nworkers, dt*nworkers, ))\n",
    "\n",
    "os.system(\"mkdir -p histos/\")\n",
    "print('Saving output in %s...'%(\"histos/\" + outname + \".pkl.gz\"))\n",
    "with gzip.open(\"histos/\" + outname + \".pkl.gz\", \"wb\") as fout:\n",
    "    cloudpickle.dump(output, fout)\n",
    "print('Done!')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f9d4677e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import print_function, division\n",
    "from collections import defaultdict, OrderedDict\n",
    "import gzip\n",
    "import pickle\n",
    "import json\n",
    "import os\n",
    "import uproot\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from coffea import hist, processor\n",
    "from coffea.hist import plot\n",
    "from cycler import cycler\n",
    "\n",
    "from topcoffea.plotter.OutText import OutText\n",
    "\n",
    "\n",
    "path = 'histos/plotsTopEFT.pkl.gz'\n",
    "outname = 'temp.png'\n",
    "\n",
    "# Select variable, channel and cuts\n",
    "var = 'met'\n",
    "channel = ['eemSSonZ', 'eemSSoffZ', 'mmeSSonZ', 'mmeSSoffZ','eeeSSonZ', 'eeeSSoffZ', 'mmmSSonZ', 'mmmSSoffZ']\n",
    "cut = 'base'\n",
    "\n",
    "print('Opening path: ', path)\n",
    "hists = {}\n",
    "with gzip.open(path) as fin:\n",
    "  hin = pickle.load(fin)\n",
    "  print(' >> looking for histograms...')\n",
    "  for k in hin.keys():\n",
    "    if k in hists: hists[k]+=hin[k]\n",
    "    else:          hists[k]=hin[k]\n",
    "\n",
    "\n",
    "# Create figure\n",
    "fig, (ax, rax) = plt.subplots(2, 1, figsize=(14,7), gridspec_kw={\"height_ratios\": (3, 1)}, sharex=True)\n",
    "plt.subplots_adjust(left=0.1, bottom=0.1, right=0.9, top=0.9)\n",
    "\n",
    "# Select the histogram var, channel and cut\n",
    "h = hists[var]\n",
    "h = h.integrate('channel', channel)\n",
    "h = h.integrate('cut', cut)\n",
    "\n",
    "# Integrate over samples\n",
    "h = h.sum('sample')\n",
    " \n",
    "# Plot and save figure to outname\n",
    "hist.plot1d(h, ax=ax, line_opts={'color':'orange'})\n",
    "fig.savefig(outname)\n",
    "print('Output histogram saved in %s'%outname)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "86c79e8f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
