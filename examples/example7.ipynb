{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "%matplotlib inline\n",
    "from coffea import hist\n",
    "import coffea.processor as processor\n",
    "import awkward as ak"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This program will graph the sum of Jet pT's which are greater than 30 GeV and farther than a Euclidean distance of 0.4 from any lepton with pT > 10 GeV.\n",
    "class Processor(processor.ProcessorABC):\n",
    "    def __init__(self):\n",
    "        dataset_axis = hist.Cat(\"dataset\", \"\")\n",
    "        muon_axis = hist.Bin(\"Jet_pt\", \"Jet_pt [GeV]\", 100, 15, 200)\n",
    "        \n",
    "        self._accumulator = processor.dict_accumulator({\n",
    "            'Jet_pt': hist.Hist(\"Counts\", dataset_axis, muon_axis),\n",
    "            'cutflow': processor.defaultdict_accumulator(int)\n",
    "        })\n",
    "    \n",
    "    @property\n",
    "    def accumulator(self):\n",
    "        return self._accumulator\n",
    "    \n",
    "    def process(self, events):\n",
    "        output = self.accumulator.identity()\n",
    "        \n",
    "        dataset = events.metadata[\"dataset\"]\n",
    "\n",
    "        muons = events.Muon\n",
    "        electrons = events.Electron\n",
    "        jets = events.Jet\n",
    "        \n",
    "        output['cutflow']['all events'] += ak.size(jets, axis=0)\n",
    "        output['cutflow']['all jets'] += ak.sum(ak.count(jets, axis=1))\n",
    "        \n",
    "        # Get jets with higher GeV than 30.\n",
    "        min_jetpt = (jets.pt > 30)\n",
    "        output['cutflow']['jets with pt > 30'] += ak.sum(ak.sum(min_jetpt, axis=1))\n",
    "        \n",
    "        # Get all leptons with higher GeV than 10.\n",
    "        min_muonpt = (muons.pt > 10)\n",
    "        output['cutflow']['muons with pt > 10'] += ak.sum(ak.sum(min_muonpt, axis=1))\n",
    "        min_electronpt = (electrons.pt > 10)\n",
    "        output['cutflow']['electrons with pt > 10'] += ak.sum(ak.sum(min_electronpt, axis=1))\n",
    "        \n",
    "        # Mask jets and leptons with their minimum requirements/\n",
    "        goodjets = jets[min_jetpt]\n",
    "        goodmuons = muons[min_muonpt]\n",
    "        goodelectrons = electrons[min_electronpt]\n",
    "    \n",
    "        jet_muon_pairs = ak.cartesian({'jets': goodjets, 'muons': goodmuons}, nested=True)\n",
    "        jet_electron_pairs = ak.cartesian({'jets': goodjets, 'electrons': goodelectrons}, nested=True)\n",
    "    \n",
    "        # This long conditional checks that the jet is at least 0.4 euclidean distance from each lepton. It then checks if each unique jet contains a False, i.e., that a jet is 0.4 euclidean distance from EVERY specific lepton in the event.\n",
    "        good_jm_pairs = goodjets.nearest(goodmuons).delta_r(goodjets) > 0.4\n",
    "        good_je_pairs = goodjets.nearest(goodelectrons).delta_r(goodjets) > 0.4\n",
    "        good_jl_pairs = good_jm_pairs & good_je_pairs\n",
    "        \n",
    "        output['cutflow']['jet-muon pairs'] += ak.sum(ak.sum(good_jm_pairs, axis=1))\n",
    "        output['cutflow']['jet-electron pairs'] += ak.sum(ak.sum(good_je_pairs, axis=1))\n",
    "        output['cutflow']['jet-lepton pairs'] += ak.sum(ak.sum(good_jl_pairs, axis=1))\n",
    "        \n",
    "        # We then mask our jets with all three of the above good pairs to get only jets that are 0.4 distance from every type of lepton, and sum them.\n",
    "        sumjets = ak.sum(goodjets[good_jl_pairs].pt, axis=1)\n",
    "        output['cutflow']['final jets'] += ak.sum(ak.count(goodjets[good_jl_pairs], axis=1))\n",
    "        output['Jet_pt'].fill(dataset=dataset, Jet_pt=sumjets)\n",
    "        \n",
    "        return output\n",
    "\n",
    "    def postprocess(self, accumulator):\n",
    "        return accumulator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8e57431cd7e344678a56551d123882ce",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='Preprocessing', max=1.0, style=ProgressStyle(description_…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "090bb3e6c45a45c2b74f7606a8a859b9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='Processing', max=214.0, style=ProgressStyle(description_w…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/hep/madamec/.conda/envs/coffea/lib/python3.7/site-packages/coffea/nanoevents/schemas/nanoaod.py:133: RuntimeWarning: Parsing indexer Muon_genPartIdx, expected to find collection GenPart but did not\n",
      "  warnings.warn(str(problem), RuntimeWarning)\n",
      "/home/hep/madamec/.conda/envs/coffea/lib/python3.7/site-packages/coffea/nanoevents/schemas/nanoaod.py:133: RuntimeWarning: Parsing indexer Photon_genPartIdx, expected to find collection GenPart but did not\n",
      "  warnings.warn(str(problem), RuntimeWarning)\n",
      "/home/hep/madamec/.conda/envs/coffea/lib/python3.7/site-packages/coffea/nanoevents/schemas/nanoaod.py:133: RuntimeWarning: Parsing indexer Tau_genPartIdx, expected to find collection GenPart but did not\n",
      "  warnings.warn(str(problem), RuntimeWarning)\n",
      "/home/hep/madamec/.conda/envs/coffea/lib/python3.7/site-packages/coffea/nanoevents/schemas/nanoaod.py:133: RuntimeWarning: Parsing indexer Electron_genPartIdx, expected to find collection GenPart but did not\n",
      "  warnings.warn(str(problem), RuntimeWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Received SIGINT, killed pending jobs.  Running jobs will continue to completion.\n",
      "Running jobs: 3\n"
     ]
    }
   ],
   "source": [
    "fileset = {'SingleMu' : [\"root://eospublic.cern.ch//eos/root-eos/benchmark/Run2012B_SingleMu.root\"]}\n",
    "\n",
    "# Our file is missing some cross-references, so we have to make NanoAOD push warnings instead of erroring out.\n",
    "# This ultimately isn't a problem, it's just a constraint of the public NanoAOD we're using.\n",
    "processor.NanoAODSchema.warn_missing_crossrefs = True\n",
    "\n",
    "output = processor.run_uproot_job(fileset=fileset, \n",
    "                       treename=\"Events\", \n",
    "                       processor_instance=Processor(),\n",
    "                       executor=processor.futures_executor,\n",
    "                       executor_args={'schema': processor.NanoAODSchema},\n",
    "                       chunksize=250000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hist.plot1d(output['Jet_pt'], overlay='dataset', fill_opts={'edgecolor': (0,0,0,0.3), 'alpha': 0.8})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for key, value in output['cutflow'].items():\n",
    "    print(key, value)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = ak.Array([['a', 'b', 'c'], ['d', 'e']])\n",
    "b = ak.Array([[1, 2], [3, 4, 5]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "c = ak.cartesian([a, b], nested=True)\n",
    "d = ak.to_list(c)\n",
    "d"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "d[0][:][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "coffea",
   "language": "python",
   "name": "coffea"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
