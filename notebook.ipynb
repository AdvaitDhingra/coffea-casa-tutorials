{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1>PyHEP 2020: A Practical Analysis in Coffea</h1>\n",
    "<hr />\n",
    "<h2>Introduction</h2>\n",
    "<p>This tutorial will be going through a practical analysis (single top-Higgs production) done in Coffea. The cuts demanded by the analysis, as well as how they are implemented in Coffea, will first be detailed step-by-step. At the end, these steps will be wrapped up in the Coffea processor class, and I will run on a Dask cluster premiered earlier this week by Oksana Shadura with real CMS data, as a proof of Coffea deployment.</p>\n",
    "\n",
    "\n",
    "<h2>Review(?)</h2>\n",
    "<p>We begin by loading in a sample file used in the analysis, and the NanoEvents package within Coffea.</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from coffea.nanoaod import NanoEvents\n",
    "\n",
    "file = \"root://xrootd.unl.edu//store/mc/RunIISummer16NanoAODv5/THQ_Hincl_13TeV-madgraph-pythia8_TuneCUETP8M1/NANOAODSIM/PUMoriond17_Nano1June2019_102X_mcRun2_asymptotic_v7-v1/100000/38E83594-51BD-7D46-B96D-620DD60078A7.root\"\n",
    "events = NanoEvents.from_file(file)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p>This loads in the test file in events, which has a jagged array structure that stores all of the file's events. We can see what attributes the events have by calling the .columns attribute.</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[<event 0> <event 1> <event 2> ... <event 614397> <event 614398> <event 614399>]\n",
      "\n",
      "\n",
      "['PSWeight', 'SubJet', 'fixedGridRhoFastjetCentral', 'GenMET', 'PuppiMET', 'fixedGridRhoFastjetCentralNeutral', 'genTtbarId', 'LHEPart', 'Flag', 'SoftActivityJetNjets5', 'GenPart', 'fixedGridRhoFastjetAll', 'SoftActivityJetNjets2', 'Tau', 'Pileup', 'HLTriggerFirstPath', 'fixedGridRhoFastjetCentralCalo', 'run', 'TrigObj', 'event', 'btagWeight', 'LHEReweightingWeight', 'LHE', 'MET', 'GenVisTau', 'SubGenJetAK8', 'TkMET', 'CorrT1METJet', 'luminosityBlock', 'SoftActivityJetHT', 'fixedGridRhoFastjetCentralChargedPileUp', 'HLTriggerFinalPath', 'Electron', 'ChsMET', 'CaloMET', 'FatJet', 'RawMET', 'L1PreFiringWeight', 'HTXS', 'Muon', 'Jet', 'L1', 'Photon', 'SoftActivityJetHT10', 'SoftActivityJet', 'GenJet', 'Generator', 'PV', 'LHEPdfWeight', 'GenJetAK8', 'SoftActivityJetHT5', 'SoftActivityJetNjets10', 'SV', 'LHEWeight', 'GenDressedLepton', 'SoftActivityJetHT2', 'IsoTrack', 'OtherPV', 'L1simulation', 'genWeight', 'LHEScaleWeight', 'HLT']\n"
     ]
    }
   ],
   "source": [
    "print(events)\n",
    "print('\\n')\n",
    "print(events.columns)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And we can easily access any of those attributes. For example, 'Muon':"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<MuonArray [[<Muon 0> <Muon 1>] [] [<Muon 2>] ... [<Muon 622043> <Muon 622044>] [<Muon 622045>] [<Muon 622046>]] at 0x7f5e75f6fb10>"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "events.Muon"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p>And, similarly, we can easily access any of the attributes that the 'Muon' column has (for example, pt):</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['dxy', 'dxyErr', 'dz', 'dzErr', 'eta', 'ip3d', 'jetPtRelv2', 'jetRelIso', 'mass', 'miniPFRelIso_all', 'miniPFRelIso_chg', 'pfRelIso03_all', 'pfRelIso03_chg', 'pfRelIso04_all', 'phi', 'pt', 'ptErr', 'segmentComp', 'sip3d', 'tkRelIso', 'tunepRelPt', 'mvaLowPt', 'mvaTTH', 'charge', 'nStations', 'nTrackerLayers', 'pdgId', 'tightCharge', 'highPtId', 'inTimeMuon', 'isGlobal', 'isPFcand', 'isTracker', 'looseId', 'mediumId', 'mediumPromptId', 'miniIsoId', 'multiIsoId', 'mvaId', 'pfIsoId', 'softId', 'softMvaId', 'tightId', 'tkIsoId', 'triggerIdLoose', 'genPartFlav', 'cleanmask', 'matched_jet', 'matched_gen']\n",
      "\n",
      "\n",
      "[[48.43083 32.657864] [] [61.244366] ... [6.901195 6.2357697] [68.91875] [3.0041604]]\n"
     ]
    }
   ],
   "source": [
    "print(events.Muon.columns)\n",
    "print('\\n')\n",
    "print(events.Muon.pt)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, an important component of columnar analysis is the concept of masking. We can mask an array with some condition, which returns to us an array of the same shape, but filled with True/False, based on whether each element in that array meets the condition or not. We can apply this mask to the original array to 'kick out' all the False statements, leaving us with True's. For example, say we want muons with pt > 40:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[<Muon 0> <Muon 1>] [] [<Muon 2>] ... [<Muon 622043> <Muon 622044>] [<Muon 622045>] [<Muon 622046>]]\n",
      "\n",
      "\n",
      "[[48.43083 32.657864] [] [61.244366] ... [6.901195 6.2357697] [68.91875] [3.0041604]]\n",
      "\n",
      "\n",
      "[[<Muon 0>] [] [<Muon 2>] ... [] [<Muon 622045>] []]\n"
     ]
    }
   ],
   "source": [
    "muons = events.Muon\n",
    "\n",
    "print(muons)\n",
    "print('\\n')\n",
    "print(muons.pt)\n",
    "print('\\n')\n",
    "print(muons[muons.pt > 40])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p>As you can see above, the first subarray of Muon has two muons, one of which has pt > 40, and the other of which doesn't. In the last line, we see that the one which doesn't has been booted out, and we're left with the ones we want. Easy!</p>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2>Lepton Selection</h2>\n",
    "<p>So, after that review, let's now begin with some lepton selection, for which the Muon column we've selected to view above is a perfect fit. Borrowing from the draft note of [TODO: CITATION HERE], we're provided these requirements for muons:</p>\n",
    "\n",
    "| Cut                      | Loose        | Tight        |\n",
    "|--------------------------|--------------|--------------|\n",
    "| $\\eta$ < 2.4             | $\\checkmark$ | $\\checkmark$ |\n",
    "| $p_T$                    | > 5 GeV      | > 15 GeV     |\n",
    "| \\|$d_{xy}$\\| < 0.05 (cm) | $\\checkmark$ | $\\checkmark$ |\n",
    "| \\|$d_z$\\| < 0.1 (cm)     | $\\checkmark$ | $\\checkmark$ |\n",
    "| SIP$_{3D}$ < 8           | $\\checkmark$ | $\\checkmark$ |\n",
    "| I$_{mini}$ < 0.4         | $\\checkmark$ | $\\checkmark$ |\n",
    "| is Loose Muon            | $\\checkmark$ | $\\checkmark$ |\n",
    "| jet CSV                  | -            | < 0.8484     |\n",
    "| is Medium Muon           | -            | $\\checkmark$ |\n",
    "| tight-charge             | -            | $\\checkmark$ |\n",
    "| lepMVA > 0.90            | -            | $\\checkmark$ |\n",
    "\n",
    "How would we make these cuts in a columnar fashion? Almost exactly the same way as printed, actually! All we have to do is mask the Muon array with a boolean array that represents muons which pass the loose cuts (in one case) and tight cuts (in the other). The only intermediate step is figuring out column labels; I've left in an extra cell if you want to poke at a specific column's structure:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['dxy', 'dxyErr', 'dz', 'dzErr', 'eta', 'ip3d', 'jetPtRelv2', 'jetRelIso', 'mass', 'miniPFRelIso_all', 'miniPFRelIso_chg', 'pfRelIso03_all', 'pfRelIso03_chg', 'pfRelIso04_all', 'phi', 'pt', 'ptErr', 'segmentComp', 'sip3d', 'tkRelIso', 'tunepRelPt', 'mvaLowPt', 'mvaTTH', 'charge', 'nStations', 'nTrackerLayers', 'pdgId', 'tightCharge', 'highPtId', 'inTimeMuon', 'isGlobal', 'isPFcand', 'isTracker', 'looseId', 'mediumId', 'mediumPromptId', 'miniIsoId', 'multiIsoId', 'mvaId', 'pfIsoId', 'softId', 'softMvaId', 'tightId', 'tkIsoId', 'triggerIdLoose', 'genPartFlav', 'cleanmask', 'matched_jet', 'matched_gen']\n",
      "\n",
      "\n",
      "[[True True] [] [True] ... [True True] [True] [True]]\n"
     ]
    }
   ],
   "source": [
    "print(muons.columns)\n",
    "print('\\n')\n",
    "print(muons.mediumId)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "loose_muons = muons[(np.abs(muons.eta) < 2.4) &\n",
    "                    (muons.pt > 5) &\n",
    "                    (np.abs(muons.dxy) < 0.05) &\n",
    "                    (np.abs(muons.dz) < 0.1) &\n",
    "                    (muons.sip3d < 8) &\n",
    "                    (muons.miniPFRelIso_all < 0.4) &\n",
    "                    (muons.looseId)]\n",
    "                    # Note that no other cuts are necessary for loose muons!\n",
    "\n",
    "# To construct the tight cut, we may as well make use of the loose cut, since they overlap.\n",
    "tight_muons = loose_muons[(loose_muons.pt > 15) &\n",
    "                         (loose_muons.mediumId) &\n",
    "                         (loose_muons.mvaTTH > 0.9)]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p>Okay, so we now successfully have a set of leptons passing each cut to work with. All muons which failed the loose cut won't be showing up from this point forward. Let's do the same thing for electrons, which is slightly complicated because the cuts fall into a set of two ranges: 0 < |$\\eta$| < 1.479 and 1.479 < |$\\eta$| < 2.5. These are listed respectively in parentheses: (range 1, range 2).</p>\n",
    "\n",
    "| Cut                                     | Loose        | Tight        |\n",
    "|-----------------------------------------|--------------|--------------|\n",
    "| $\\eta$ < 2.5                            | $\\checkmark$ | $\\checkmark$ |\n",
    "| $p_T$                                   | > 7 GeV      | > 15 GeV     |\n",
    "| \\|$d_{xy}$\\| < 0.05 (cm)                | $\\checkmark$ | $\\checkmark$ |\n",
    "| \\|$d_z$\\| < 0.1 (cm)                    | $\\checkmark$ | $\\checkmark$ |\n",
    "| I$_{mini}$ < 0.4                        | $\\checkmark$ | $\\checkmark$ |\n",
    "| Number of missing hits                  | < 2          | == 0         |\n",
    "| tight-charge                            | -            | $\\checkmark$ |\n",
    "| conversion rejection                    | -            | $\\checkmark$ |\n",
    "| lepMVA > 0.90                           | -            | $\\checkmark$ |\n",
    "| MVA ID > (0.0, 0.7)                     | $\\checkmark$ | $\\checkmark$ |\n",
    "| $\\sigma_{i\\eta i\\eta}$ < (0.011, 0.030) | -            | $\\checkmark$ |\n",
    "| H/E < (0.10, 0.07)                      | -            | $\\checkmark$ |\n",
    "| -0.05 < 1/E - 1/p < (0.010, 0.005)      | -            | $\\checkmark$ |\n",
    "\n",
    "Let's put these cuts into action! A cell has been provided, again, for column-prodding purposes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['deltaEtaSC', 'dr03EcalRecHitSumEt', 'dr03HcalDepth1TowerSumEt', 'dr03TkSumPt', 'dr03TkSumPtHEEP', 'dxy', 'dxyErr', 'dz', 'dzErr', 'eCorr', 'eInvMinusPInv', 'energyErr', 'eta', 'hoe', 'ip3d', 'jetPtRelv2', 'jetRelIso', 'mass', 'miniPFRelIso_all', 'miniPFRelIso_chg', 'mvaFall17V1Iso', 'mvaFall17V1noIso', 'mvaFall17V2Iso', 'mvaFall17V2noIso', 'mvaSpring16GP', 'mvaSpring16HZZ', 'pfRelIso03_all', 'pfRelIso03_chg', 'phi', 'pt', 'r9', 'sieie', 'sip3d', 'mvaTTH', 'charge', 'cutBased', 'cutBased_Fall17_V1', 'cutBased_HLTPreSel', 'cutBased_Spring15', 'cutBased_Sum16', 'pdgId', 'tightCharge', 'vidNestedWPBitmap', 'vidNestedWPBitmapSpring15', 'vidNestedWPBitmapSum16', 'convVeto', 'cutBased_HEEP', 'isPFcand', 'lostHits', 'mvaFall17V1Iso_WP80', 'mvaFall17V1Iso_WP90', 'mvaFall17V1Iso_WPL', 'mvaFall17V1noIso_WP80', 'mvaFall17V1noIso_WP90', 'mvaFall17V1noIso_WPL', 'mvaFall17V2Iso_WP80', 'mvaFall17V2Iso_WP90', 'mvaFall17V2Iso_WPL', 'mvaFall17V2noIso_WP80', 'mvaFall17V2noIso_WP90', 'mvaFall17V2noIso_WPL', 'mvaSpring16GP_WP80', 'mvaSpring16GP_WP90', 'mvaSpring16HZZ_WPL', 'seedGain', 'genPartFlav', 'cleanmask', 'matched_jet', 'matched_gen', 'matched_photon']\n",
      "\n",
      "\n",
      "[[] [0 0] [0 0 0] ... [1] [0] [0]]\n"
     ]
    }
   ],
   "source": [
    "print(events.Electron.columns)\n",
    "print('\\n')\n",
    "print(events.Electron.lostHits)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "electrons = events.Electron\n",
    "\n",
    "loose_electrons = electrons[(np.abs(electrons.eta) < 2.5) &\n",
    "                           (electrons.pt > 7) &\n",
    "                           (np.abs(electrons.dxy) < 0.05) &\n",
    "                           (np.abs(electrons.dz) < 0.1) &\n",
    "                           (electrons.miniPFRelIso_all < 0.4) &\n",
    "                           (electrons.lostHits < 2) &\n",
    "                           # The scary one, the only one with two ranges in loose selection. \n",
    "                           (((electrons.mvaFall17V2noIso > 0) & (np.abs(electrons.eta) < 1.479)) |\n",
    "                            ((electrons.mvaFall17V2noIso > 0.7) & (np.abs(electrons.eta) > 1.479) & (np.abs(electrons.eta) < 2.5)))]\n",
    "\n",
    "# Again, all tight leptons pass the loose cut, so we may as well cut down on passing the same cuts twice.\n",
    "tight_electrons = loose_electrons[(loose_electrons.pt > 15) &\n",
    "                                 (loose_electrons.lostHits == 0) &\n",
    "                                 (loose_electrons.tightCharge > 0) &\n",
    "                                 (loose_electrons.convVeto) &\n",
    "                                 (loose_electrons.mvaTTH > 0.90) &\n",
    "                                 # Two ranges for sigma_ieie.\n",
    "                                 (((np.abs(loose_electrons.eta) < 1.479) & (loose_electrons.sieie < 0.011)) | \n",
    "                                 ((np.abs(loose_electrons.eta) < 2.5) & (np.abs(loose_electrons.eta) > 1.479) & (loose_electrons.sieie < 0.03))) &\n",
    "                                 # Two ranges for H/E\n",
    "                                 (((np.abs(loose_electrons.eta) < 1.479) & (loose_electrons.hoe < 0.1)) | \n",
    "                                 ((np.abs(loose_electrons.eta) < 2.5) & (np.abs(loose_electrons.eta) > 1.479) & (loose_electrons.hoe < 0.07))) &\n",
    "                                 # Two ranges for 1/E - 1/p\n",
    "                                 (((np.abs(loose_electrons.eta) < 1.479) & (loose_electrons.eInvMinusPInv < 0.01) & (loose_electrons.eInvMinusPInv > -0.05)) |\n",
    "                                 ((np.abs(loose_electrons.eta) < 2.5) & (np.abs(loose_electrons.eta) > 1.479) & (loose_electrons.eInvMinusPInv < 0.005) & (loose_electrons.eInvMinusPInv > -0.05)))]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2>Event Selections</h2>\n",
    "<p>So, now we have all the leptons we need, categorized by the cuts they pass. Let's get on to some event-level selections! Referring to our analysis draft note again:</p>\n",
    "\n",
    "| Both Channels                                                                                              \t| Dilepton Channel                              \t| Three-Lepton Channel                          \t|\n",
    "|------------------------------------------------------------------------------------------------------------\t|-----------------------------------------------\t|-----------------------------------------------\t|\n",
    "| No loose leptons with $m_{ll}$ < 12 GeV                                                                    \t| Exactly two tight same-sign leptons           \t| Exactly three tight leptons                   \t|\n",
    "| One or more jets passing $p_T$ > 25 GeV and \\|$\\eta$\\| < 2.4                                               \t| $p_T$ > 25/15 GeV                             \t| $p_T$ > 25/15/15 GeV                          \t|\n",
    "| One or more jets failing both the above criterion,<br>AND not qualifying $p_T$ > 40 and \\|$\\eta$\\| > 2.4. \t| No ee events with \\|$m_{ee} - m_Z$\\| < 10 GeV \t| No OSSF pair with \\|$m_{ll} - m_Z$\\| < 15 GeV \t|\n",
    "|                                                                                                            \t| Triple charge consistent electrons            \t|                                               \t|\n",
    "|                                                                                                            \t| Muons with $\\Delta p_T / p_T$ < 0.2           \t|                                               \t|\n",
    "\n",
    "<p>Coffea reaches some limitations here, as we are forced to deal not with muons and electrons, but with leptons as a whole. There are many ways, for example, that the three-lepton requirement could be met: eee, mumumu, eemu, emumu.</p>\n",
    "\n",
    "<p>In a columnar analysis approach, we'd have to consider each of these combinations of leptons. With two leptons to choose from, and repetition allowed, this leads to n+1 lines to address, n being how many leptons you're selecting. This isn't very nice, because you're (at least temporarily) splitting your selection into n+1 subsets, which is neither consistent across n (in this case, we want both 2 and 3) nor is it particularly succinct.</p>\n",
    "\n",
    "<p>In this case, I made the decision to 'step out' of the columnar approach, and go to a more familiar event loop-like solution. I wrote a function which takes as input flat arrays of muons and electrons, as well as starts/stops that help maintain their jagged structure, like so:</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[] [84.48751 27.30925] [89.66919 9.768386 6.686062] ... [40.746773] [10.835047] [19.767996]]\n",
      "\n",
      "\n",
      "[84.48751 27.30925 89.66919 ... 40.746773 10.835047 19.767996]\n",
      "\n",
      "\n",
      "[     0      0      2 ... 788264 788265 788266]\n",
      "[     0      2      5 ... 788265 788266 788267]\n"
     ]
    }
   ],
   "source": [
    "print(electrons.pt)\n",
    "print('\\n')\n",
    "print(electrons.pt.content)\n",
    "print('\\n')\n",
    "print(electrons.pt.starts)\n",
    "print(electrons.pt.stops)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p>You'll notice that the '.content' attribute gives a flat array, the '.starts' attribute returns the beginnings of each subarray, and the '.stops' attributes returns the ends of each subarray. In combination, this allows us to run a loop over the flat array, reconstruct each subarray of muons+electrons, and accept or reject it based on the cuts above. The accept/reject output is put into a boolean array, which we can mask our original jagged events array by to kick out events which don't pass the cut. Complicated, but arguably better than wading deeper and deeper into combinations of events. The resultant function for the loose lepton requirement, for example, looks like this:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This is a helper function which adds up the mass of two 4-vectors based on their components.\n",
    "def massAddition(l1_px, l1_py, l1_pz, l1_E,\n",
    "                 l2_px, l2_py, l2_pz, l2_E):\n",
    "    return np.sqrt((l1_E + l2_E)**2 - \n",
    "                  ((l1_px + l2_px)**2 + \n",
    "                   (l1_py + l2_py)**2 + \n",
    "                   (l1_pz + l2_pz)**2))\n",
    "\n",
    "# This is a helper function which gets all pairs of values of an input array.\n",
    "def combinations(array):\n",
    "    combos = [(0, 0)]\n",
    "    for i in array:\n",
    "        for j in array:\n",
    "            if ((i, j) not in combos) and ((j, i) not in combos) and (j != i):\n",
    "                combos.append((i, j))\n",
    "    return combos[1:]\n",
    "\n",
    "def looseFilter(loose_e_starts, loose_e_stops, loose_mu_starts, loose_mu_stops,\n",
    "               loose_e_px, loose_e_py, loose_e_pz, loose_e_E,\n",
    "               loose_mu_px, loose_mu_py, loose_mu_pz, loose_mu_E):\n",
    "    \n",
    "    # All events pass by default, if they do not, we turn the 1's to 0's.\n",
    "    final_mask = np.ones(loose_e_starts.size, dtype=np.bool_)\n",
    "    \n",
    "    # With the starts and stops, we can get each event's data per-event, and work with concatenated e's and mu's.\n",
    "    for e_start, e_stop, mu_start, mu_stop, i in zip(loose_e_starts, loose_e_stops, loose_mu_starts, loose_mu_stops, range(0, loose_e_starts.size)):\n",
    "        event_E = np.concatenate((loose_e_E[e_start:e_stop], loose_mu_E[mu_start:mu_stop]))\n",
    "        event_px = np.concatenate((loose_e_px[e_start:e_stop], loose_mu_px[mu_start:mu_stop]))\n",
    "        event_py = np.concatenate((loose_e_py[e_start:e_stop], loose_mu_py[mu_start:mu_stop]))\n",
    "        event_pz = np.concatenate((loose_e_pz[e_start:e_stop], loose_mu_pz[mu_start:mu_stop]))\n",
    "        # This handles empty events.\n",
    "        if event_E.size == 0:\n",
    "            final_mask[i] = 0\n",
    "        # Generate every pair, check that their combined mass is greater than 12 (if not, change 1 to 0 in mask)\n",
    "        for combination in np.array(combinations(np.argsort(event_E))):\n",
    "            if 12 > (massAddition(event_px[combination[0]], event_py[combination[0]], event_pz[combination[0]], event_E[combination[0]],\n",
    "                           event_px[combination[1]], event_py[combination[1]], event_pz[combination[1]], event_E[combination[1]])):\n",
    "                final_mask[i] = 0\n",
    "    return final_mask\n",
    "\n",
    "mask = looseFilter(loose_electrons.starts, loose_electrons.stops, loose_muons.starts, loose_muons.stops,\n",
    "            loose_electrons.x.content, loose_electrons.y.content, loose_electrons.z.content, loose_electrons.energy.content,\n",
    "            loose_muons.x.content, loose_muons.y.content, loose_muons.z.content, loose_muons.energy.content)\n",
    "\n",
    "loose_electrons = loose_electrons[mask]\n",
    "tight_electrons = tight_electrons[mask]\n",
    "loose_muons = loose_muons[mask]\n",
    "tight_muons = tight_muons[mask]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Okay, uglier. Not columnar, but it's more general, the goal is clearer, and Coffea allows us the flexibility. The loose mass requirement is handled this way, as are both channel requirements (not included here for redundancy; see analysis). We combine all of the masks that these functions give us, and we end up with a boolean array that accepts/rejects events based on whether or not they pass our required checks. If we apply this mask to our loose and tight lepton arrays, we end up with leptons that pass both the lepton selection and event selection requirements, minus the jet cut-offs. The jet cut-offs can be handled in columnar fashion, since we deal only with jets (no cross-lepton business!):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "loose_wp = 0.5425\n",
    "medium_wp = 0.8484\n",
    "        \n",
    "jets = events.Jet\n",
    "# Jets must have pt > 25 in any case.\n",
    "jets = jets[jets.pt > 25]\n",
    "    \n",
    "jetMask_medium = ((np.abs(jets.eta) < 2.4) & \n",
    "                  (jets.btagCSVV2 > medium_wp)).sum() >= 1\n",
    "jetMask_loose = (((np.abs(jets.eta) < 2.4) | ((jets.pt > 40) & (np.abs(jets.eta) > 2.4))) &\n",
    "                 (jets.btagCSVV2 <= loose_wp)).sum() >= 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The jet masks, of course, join the function-generated masks for determination of event acceptance/rejection."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2>Plotting</h2>\n",
    "<p>We have now made all of the cuts we need to plot some relevant data. Instead of doing so on the single sample file, without the appropriate functional masks, I will now run the actual analysis on a larger (but time-manageable) subset of data. In order to do this, we bundle all of the above cuts and selections into the Coffea processor class. This gives us additional tools for scale-out, and allows us to interface with Dask, which is what I will be doing, on the analysis facility which was presented earlier by Oksana Shadura.</p>\n",
    "<p>We don't dare to try to give the reins to potentially hundreds of people, yet, but you can run the analysis elsewhere, without Dask integration, by running the analysis-local.ipynb file in the directory here [TODO]. Otherwise, just watch!</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
